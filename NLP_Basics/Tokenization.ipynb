{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5b762d",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is the process of breaking text or data into smaller units called tokens (like words, subwords, or characters).\n",
    "Itâ€™s used in NLP and security to analyze text or replace sensitive data with safe placeholders.\n",
    "\n",
    "- Corpus: A large collection of text data used for analysis or training NLP models.\n",
    "- Document: A single text file or piece of content within a corpus.\n",
    "- Paragraph: A block of related sentences within a document.\n",
    "- Sentence: A grammatical unit expressing a complete thought.\n",
    "- Token: The smallest unit of text (word, subword, or symbol) after tokenization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce08ae",
   "metadata": {},
   "source": [
    "**NLTK** is a Python library focused on teaching and research in NLP, offering many algorithms and datasets.\n",
    "\n",
    "**spaCy** is a fast, production-ready NLP library with efficient pipelines and pretrained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install nltk library\n",
    "# pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43525836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. \n",
      "The ultimate goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP encompasses a variety of tasks, \n",
      "including text analysis, sentiment analysis, machine translation, speech recognition, and chatbot development. By leveraging techniques from linguistics, computer science, and machine learning, \n",
      "NLP aims to bridge the gap between human communication and computer understanding, enabling more intuitive and efficient interactions with technology.\n"
     ]
    }
   ],
   "source": [
    "## Lets create a corpus\n",
    "corpus = \"\"\"Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. \n",
    "The ultimate goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP encompasses a variety of tasks, \n",
    "including text analysis, sentiment analysis, machine translation, speech recognition, and chatbot development. By leveraging techniques from linguistics, computer science, and machine learning, \n",
    "NLP aims to bridge the gap between human communication and computer understanding, enabling more intuitive and efficient interactions with technology.\"\"\"\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e65aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language.\n",
      "The ultimate goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
      "NLP encompasses a variety of tasks, \n",
      "including text analysis, sentiment analysis, machine translation, speech recognition, and chatbot development.\n",
      "By leveraging techniques from linguistics, computer science, and machine learning, \n",
      "NLP aims to bridge the gap between human communication and computer understanding, enabling more intuitive and efficient interactions with technology.\n"
     ]
    }
   ],
   "source": [
    "## Tokenization\n",
    "## Paragraph into sentences\n",
    "from nltk.tokenize import sent_tokenize         ## to tokenize sentences\n",
    "documents = sent_tokenize(corpus)\n",
    "## sentences is a list so for reading pupouse we can use for loop\n",
    "for i in documents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e5967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.', 'The', 'ultimate', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful', '.', 'NLP', 'encompasses', 'a', 'variety', 'of', 'tasks', ',', 'including', 'text', 'analysis', ',', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'speech', 'recognition', ',', 'and', 'chatbot', 'development', '.', 'By', 'leveraging', 'techniques', 'from', 'linguistics', ',', 'computer', 'science', ',', 'and', 'machine', 'learning', ',', 'NLP', 'aims', 'to', 'bridge', 'the', 'gap', 'between', 'human', 'communication', 'and', 'computer', 'understanding', ',', 'enabling', 'more', 'intuitive', 'and', 'efficient', 'interactions', 'with', 'technology', '.']\n",
      "----------------------------------------------------------------------------\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.']\n",
      "['The', 'ultimate', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful', '.']\n",
      "['NLP', 'encompasses', 'a', 'variety', 'of', 'tasks', ',', 'including', 'text', 'analysis', ',', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'speech', 'recognition', ',', 'and', 'chatbot', 'development', '.']\n",
      "['By', 'leveraging', 'techniques', 'from', 'linguistics', ',', 'computer', 'science', ',', 'and', 'machine', 'learning', ',', 'NLP', 'aims', 'to', 'bridge', 'the', 'gap', 'between', 'human', 'communication', 'and', 'computer', 'understanding', ',', 'enabling', 'more', 'intuitive', 'and', 'efficient', 'interactions', 'with', 'technology', '.']\n"
     ]
    }
   ],
   "source": [
    "## Paragraph into words\n",
    "from nltk.tokenize import word_tokenize         ## to tokenize words\n",
    "words = word_tokenize(corpus)\n",
    "print(words)\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27400b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.', 'The', 'ultimate', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful', '.', 'NLP', 'encompasses', 'a', 'variety', 'of', 'tasks', ',', 'including', 'text', 'analysis', ',', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'speech', 'recognition', ',', 'and', 'chatbot', 'development', '.', 'By', 'leveraging', 'techniques', 'from', 'linguistics', ',', 'computer', 'science', ',', 'and', 'machine', 'learning', ',', 'NLP', 'aims', 'to', 'bridge', 'the', 'gap', 'between', 'human', 'communication', 'and', 'computer', 'understanding', ',', 'enabling', 'more', 'intuitive', 'and', 'efficient', 'interactions', 'with', 'technology', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize           ## to tokenize words and punctuations\n",
    "\n",
    "words_punct = wordpunct_tokenize(corpus)\n",
    "print(words_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf72147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language.', 'The', 'ultimate', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful.', 'NLP', 'encompasses', 'a', 'variety', 'of', 'tasks', ',', 'including', 'text', 'analysis', ',', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'speech', 'recognition', ',', 'and', 'chatbot', 'development.', 'By', 'leveraging', 'techniques', 'from', 'linguistics', ',', 'computer', 'science', ',', 'and', 'machine', 'learning', ',', 'NLP', 'aims', 'to', 'bridge', 'the', 'gap', 'between', 'human', 'communication', 'and', 'computer', 'understanding', ',', 'enabling', 'more', 'intuitive', 'and', 'efficient', 'interactions', 'with', 'technology', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer           ## to tokenize using treebank tokenizer to include full stops etc. in words\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "treebank_tokens = tokenizer.tokenize(corpus)\n",
    "print(treebank_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
